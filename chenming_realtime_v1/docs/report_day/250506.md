1.[DwsTradeCartAddUuWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTradeCartAddUuWindow.java)

“加购”是一个非常重要的行为指标，代表了用户对商品的购买意向。为了更好地分析用户行为趋势，
我们需要实时统计每天每秒新增的“加购独立用户数”，即：同一用户在一秒钟内多次加购只算一次。

输入数据：Kafka 中的 dwd 层加购日志（JSON 格式），包含 user_id 和 ts_ms 时间戳字段。
输出数据：
每秒窗口内新增的独立加购用户数量（去重）；
输出格式包括窗口起止时间、日期、加购独立用户数；
将结果写入 Doris 或控制台打印用于测试。

实现思路
数据清洗转换
从 Kafka 中读取 JSON 字符串，转为 JSONObject。
设置 Watermark
提取 ts_ms 作为事件时间，使用单调递增 Watermark。
按用户分组
使用 KeyedStream 对每个用户进行分组。
状态管理去重
利用 ValueState<String> 记录用户上一次加购的日期；
如果当前加购日期不同于上次，则视为新用户，输出并更新状态；
设置状态 TTL 为一天，自动过期。
开窗聚合
使用 TumblingEventTimeWindow，每秒一个滚动窗口；
先聚合独立用户数（计数）；
再通过 AllWindowFunction 构建最终输出实体类 CartAddUuBean。
结果输出
转换为 JSON 字符串；
打印或写入 Doris。

2.[DwsTradeProvinceOrderWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTradeProvinceOrderWindow.java)

Kafka Source
↓
JSON 解析 + 过滤无效记录
↓
KeyBy 订单ID去重（幂等处理）
↓
Watermark 设置事件时间
↓
Map 转换为实体类对象
↓
KeyBy 省份ID 分组
↓
Tumbling Window 开窗聚合
↓
Async Join 维度表 dim_base_province
↓
Sink To Doris


1. 数据源读取与清洗
   从 Kafka 读取订单明细日志；
   忽略格式错误的数据，提高健壮性；
   设置消费者组、初始偏移量等参数。
2.  KeyBy + ProcessFunction 实现幂等处理
    对 order_detail.id 做分组，保证同一订单只处理一次；
    利用状态管理实现“幂等”机制，旧数据取反发送，新数据正常发送，防止重复累加；
    设置 TTL 为 10 秒，避免状态无限增长。
3. 设置 Watermark 并提取事件时间
   使用 ts 字段作为事件时间；
   使用单调递增的 Watermark，适用于大多数电商场景；
   保障窗口计算的时间一致性。
4. Map 转换为实体类对象
   构建统一的业务对象，方便下游处理；
   使用 HashSet 存储订单 ID，用于去重计数。
5. KeyBy + TumblingWindow 开窗聚合
按省份分组；
使用 10 秒滚动窗口；
使用 ReduceFunction 累加金额，使用 WindowFunction 设置窗口时间维度。
6. 异步关联维度表（Dim 表）
   使用异步 IO 提高性能；
   关联省份维度表获取省份名称；
   支持并发访问外部维度服务（如 HBase / MySQL）。
   为什么要对订单做幂等处理？
   因为 Kafka 消费可能重复消费，导致数据重复累加，需要幂等机制防止这种情况。
   为什么使用 Async I/O 关联维度表？
   避免阻塞主线程，提高查询效率，适用于并发访问外部系统。
   窗口函数使用 Reduce + WindowFunction 的组合有什么优势？
   Reduce 函数轻量高效，适合中间聚合；WindowFunction 用于补充窗口元信息。
   如果数据乱序严重怎么办？
   可以适当增加 Watermark 的延迟容忍时间，或者使用 Lateral Window。
   如何保障 Exactly-Once？
   开启 Checkpointing，并且 Sink 支持事务提交。
3.[DwsTradeSkuOrderWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTradeSkuOrderWindow.java)
1.主要用于对电商交易中的订单明细数据进行处理和分析。具体功能包括从 Kafka 中读取订单明细数据，对数据进行去重、时间窗口聚合，
然后关联多个维度表（如商品信息、品牌信息、分类信息等）
   数据去重
   按照订单明细的 id 进行分组，使用 Flink 的状态管理机制对重复数据进行去重处理。
   时间窗口处理
   指定水印和事件时间字段，按照商品 skuId 进行分组，然后使用滚动时间窗口（10 秒）对数据进行聚合。
   维度关联
   通过 AsyncDataStream.unorderedWait 方法异步关联多个维度表，包括商品信息表 dim_sku_info、商品品类表 dim_spu_info、品牌信息表 dim_base_trademark、三级分类表 dim_base_category3、二级分类表 dim_base_category2 和一级分类表 dim_base_category1。
   数据输出
   将最终处理结果转换为 JSON 字符串，并写入到 Doris 数据库的 dws_trade_sku_order_window 表中。
4.[DwsTrafficHomeDetailPageViewWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTrafficHomeDetailPageViewWindow.java)
   Kafka Source
   ↓
   JSON 解析 + 过滤（仅保留 home 和 good_detail）
   ↓
   设置 Watermark + 提取事件时间
   ↓
   KeyBy mid 去重处理（判断是否当天首次访问）
   ↓
   Map 转换为实体类对象 TrafficHomeDetailPageViewBean
   ↓
   AllWindow 全局滚动窗口聚合（10秒）
   ↓
   ReduceFunction + AllWindowFunction 聚合 UV
   ↓
   Sink To Doris
   本项目实现了以下能力：

实时性：基于 Flink 流式计算引擎，实现秒级 UV 统计；
精准性：通过 mid 分组 + 状态管理实现每日 UV 去重；
扩展性：模块化设计，易于接入其他页面类型；
稳定性：配置 Checkpoint、Restart、TTL 等机制，保障作业稳定运行。

5.[DwsTrafficSourceKeywordPageViewWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTrafficSourceKeywordPageViewWindow.java)

用户往往通过搜索行为进入商品详情页或其他页面。分析用户的搜索行为，特别是对搜索关键词的统计与分析，可以为运营和产品优化提供重要依据

Kafka Source
↓
Flink SQL 创建动态表 + Watermark
↓
过滤出 search 页面且 item_type=keyword 的记录
↓
调用自定义 UDTF 函数 ik_analyze 对搜索词进行分词
↓
按窗口（10秒）+ keyword 分组聚合
↓
Sink To Doris

 注册自定义函数
   java
   深色版本
   tenv.createTemporarySystemFunction("ik_analyze", KeywordUDTF.class);
   ✅ 说明：

ik_analyze 是一个自定义的 UDTF（表函数），用于对搜索词进行中文分词；
基于 IKAnalyzer 或其他中文分词库实现；
可以拆分“手机配件”、“华为P30”等复合词。
 创建动态表并提取事件时间字段
   sql
   深色版本
   create table page_log(
   page map<string, string>,
   ts bigint,
   et as to_timestamp_ltz(ts, 3),
   watermark for et as et - interval '5' second
   ) WITH (
   'connector' = 'kafka',
   ...
   )
   ✅ 说明：

从 Kafka 中读取 JSON 数据；
提取 ts 字段作为事件时间戳 et；
设置水位线（watermark）为 et - 5s，容忍乱序数据。
过滤出搜索行为
   sql
   深色版本
   select
   page['item'] fullword,
   et
   from page_log
   where page['last_page_id'] = 'search'
   and page['item_type'] = 'keyword'
   and page['item'] is not null
   ✅ 说明：

只保留来自搜索页（last_page_id = 'search'）的行为；
item_type = 'keyword' 表示该行为携带了搜索关键词；
fullword 表示原始搜索词。
 调用分词函数完成拆词
   sql
   深色版本
   SELECT keyword, et FROM search_table,
   LATERAL TABLE(ik_analyze(fullword)) t(keyword)
   ✅ 说明：

使用 LATERAL TABLE 结合自定义函数进行分词；
拆分成多个关键词后形成新行；
例如：手机壳 → 手机, 壳
 开窗聚合统计关键词数量
   sql
   深色版本
   SELECT
   date_format(window_start, 'yyyy-MM-dd HH:mm:ss') stt,
   date_format(window_end, 'yyyy-MM-dd HH:mm:ss') edt,
   date_format(window_start, 'yyyy-MM-dd') cur_date,
   keyword,
   count(*) keyword_count
   FROM TABLE(
   TUMBLE(TABLE split_table, DESCRIPTOR(et), INTERVAL '10' second))
   GROUP BY window_start, window_end, keyword
   ✅ 说明：

使用滚动窗口（Tumbling Window），每 10 秒一个窗口；
按照 keyword 和窗口时间分组统计；
输出每个窗口内的关键词 PV（即访问次数）。
6.[DwsTrafficVcChArIsNewPageViewWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsTrafficVcChArIsNewPageViewWindow.java)
页面浏览是最基础也是最重要的用户行为之一。通过分析用户的访问数据，我们可以了解：
不同设备版本的使用情况；
各个地区的用户活跃度；
渠道推广效果；
新老用户的留存与参与度；
这些维度可以帮助我们优化产品设计、调整运营策略、提升用户体验。
类别	内容
输入	Kafka 中的 DWD 层页面日志（JSON 格式），包含 mid、ts、common、page 等字段
输出	每 10 秒按 vc（版本）、ch（渠道）、ar（地区）、is_new（是否新用户） 维度聚合以下指标：<br>• 页面浏览数（PV）<br>• 独立访客数（UV）<br>• 跳出次数（SV）<br>• 停留总时长（durSum）
存储	将结果写入 Apache Doris，便于后续 BI 查询和可视化

Kafka Source
↓
解析 JSON 字符串 → JSONObject
↓
KeyBy(mid) → 判断是否为 UV & SV
↓
设置 Watermark + EventTime
↓
KeyBy(vc, ch, ar, is_new)
↓
开窗（Tumbling 10s）+ Reduce 聚合
↓
Sink To Doris


为什么只统计页面浏览？
页面浏览是用户行为的基础，是衡量活跃度和体验的核心指标。
如何判断用户是新用户？
根据 common.is_new 字段，由埋点系统打标决定。
为什么使用 mid 作为唯一标识？
mid 是设备级别标识，适合用来统计 UV。


7.[DwsUserUserLoginWindow.java](..%2F..%2Fsrc%2Fmain%2Fjava%2Fdws%2FDwsUserUserLoginWindow.java)
用户登录是一个重要的行为事件，通过分析用户的登录频率与间隔，可以判断：
活跃用户数量（UU）；
用户是否流失后又重新回归（回流用户）；
Kafka 中的 DWD 层页面日志（JSON 格式），包含 common.uid、page.last_page_id、ts 等字段
输出	每 10 秒统计一次：独立用户数（UU）、回流用户数（Back）
存储	将结果写入 Apache Doris，便于后续 BI 查询和可视化
Kafka Source
↓
解析 JSON 字符串 → JSONObject
↓
过滤出登录行为（last_page_id = 'login' 或 null）
↓
设置 Watermark + EventTime
↓
KeyBy(uid) → 判断是否为新用户/回流用户
↓
开窗（Tumbling 10s）+ Reduce 聚合
↓
Sink To Doris

为什么只统计登录行为？
登录是用户身份确认的关键节点，是活跃度的核心指标。
如何判断用户是回流用户？
如果用户上次登录距离本次登录超过 8 天，则认为该用户回流。
为什么使用 windowAll 而不是 keyedWindow？
我们需要的是全局的统计值，而不是每个用户维度的数据。
如果系统重启，状态会不会丢失？
不会，我们启用了 Checkpoint，并设置了状态后端为 RocksDB 或 FsStateBackend。
如何验证结果准确性？
可以通过日志打印中间数据、对比离线 Hive 统计等方式验证。

